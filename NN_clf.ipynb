{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam, Nadam, Adamax\n",
    "\n",
    "#import t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Top10_Artikel_wolf.csv')\n",
    "data = data[data.DatumZeit >= '2017-04']\n",
    "\n",
    "data['DatumZeit'] = pd.to_datetime(data['DatumZeit'])\n",
    "data[\"DayofWeek\"] = data['DatumZeit'].dt.dayofweek\n",
    "\n",
    "mean_on = ['LinkKasse', 'DayofWeek', 'LinkArtikel']\n",
    "\n",
    "for i in range(1, 1 + 3):    \n",
    "    data['lag'+str(i)] = data.groupby(by = mean_on )['Anzahl'].shift(i)\n",
    "    \n",
    "TestData = '2019-06-01'\n",
    "data = data.dropna()\n",
    "train_size = data[data.DatumZeit <= TestData].shape[0]\n",
    "train, test = data[:train_size], data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential()\n",
    "\n",
    "clf.add( Dense(64, activation='relu', input_shape=(3,) ) )\n",
    "clf.add(Dropout(0.05))\n",
    "clf.add( Dense(64, activation='relu') )\n",
    "clf.add(Dropout(0.05))\n",
    "clf.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return (keras.backend.mean(keras.backend.square(y_pred - y_true)))\n",
    "\n",
    "clf.compile( optimizer=Adamax(lr=1e-1), loss = root_mean_squared_error )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 1920 samples\n",
      "Epoch 1/5\n",
      "7600/7600 [==============================] - 0s 25us/step - loss: 2382.2774 - val_loss: 1578.9704\n",
      "Epoch 2/5\n",
      "7600/7600 [==============================] - 0s 24us/step - loss: 2325.3328 - val_loss: 1422.3992\n",
      "Epoch 3/5\n",
      "7600/7600 [==============================] - 0s 24us/step - loss: 2324.2123 - val_loss: 1291.0923\n",
      "Epoch 4/5\n",
      "7600/7600 [==============================] - 0s 24us/step - loss: 2184.8806 - val_loss: 1484.6046\n",
      "Epoch 5/5\n",
      "7600/7600 [==============================] - 0s 24us/step - loss: 2280.4733 - val_loss: 1518.9631\n"
     ]
    }
   ],
   "source": [
    "drop_nn_columns = ['DatumZeit', 'LinkKasse', 'LinkArtikel', 'Anzahl', 'DayofWeek']\n",
    "history = clf.fit(\n",
    "           train.drop(columns=drop_nn_columns), train.Anzahl, \n",
    "    epochs=5, batch_size=109,\n",
    "    validation_data=( test.drop(columns=drop_nn_columns) , test.Anzahl),\n",
    "    verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[832.71387 ],\n",
       "       [562.7478  ],\n",
       "       [ 97.14497 ],\n",
       "       ...,\n",
       "       [ 11.671348],\n",
       "       [ 17.244797],\n",
       "       [ 12.983937]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict( np.array(test.drop(columns=drop_nn_columns)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save('clf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(local Package)\n",
       " └─clf.h5"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''(t4.Package()\n",
    "     .set(\"clf.h5\")\n",
    "     #.push(\"quilt/quilt_sagemaker_demo\", \"s3://quilt-example\", registry=\"s3://quilt-example\")\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
